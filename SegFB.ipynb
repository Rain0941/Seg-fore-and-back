{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8050197,"sourceType":"datasetVersion","datasetId":4747300},{"sourceId":8052068,"sourceType":"datasetVersion","datasetId":4748597},{"sourceId":8065458,"sourceType":"datasetVersion","datasetId":4758315}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os.path as osp\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nimport os\nimport argparse\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nimport random\n\n\nseed = 43\ntorch.manual_seed(seed) # 为CPU设置随机种子\ntorch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\ntorch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\nnp.random.seed(seed)  # Numpy module.\nrandom.seed(seed)  # Python random module.\t\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\n\nDATA_DIR = \"\"  # 数据集地址\nDATA_SPLIT = \"\"  # 数据集划分文件地址\ndevice = \"cuda\"\n\nclass CUB(Dataset):\n\n    def __init__(self, setname, args):\n        IMAGE_PATH = os.path.join(args.data_dir)\n        SPLIT_PATH = os.path.join(args.data_split)\n\n        csv_path = osp.join(SPLIT_PATH, setname + '.csv')\n        lines = [x.strip() for x in open(csv_path, 'r').readlines()][1:]\n\n        data = []\n        label = []\n        lb = -1\n\n        self.wnids = []\n\n        for l in lines:\n            context = l.split(',')\n            name = context[0]\n            wnid = context[1]\n            path = osp.join(IMAGE_PATH, name)\n            if wnid not in self.wnids:\n                self.wnids.append(wnid)\n                lb += 1\n            data.append(path)\n            label.append(lb)\n\n        self.data = data  # data path of all data\n        self.label = label  # label of all data\n        self.num_class = len(set(label))\n\n        if setname == 'val' or setname == 'test':\n            image_size = 84\n            self.transform = transforms.Compose([\n                transforms.Resize([84, 84]),\n                transforms.ToTensor(),\n                transforms.Normalize(np.array([x / 255.0 for x in [125.3, 123.0, 113.9]]),\n                                     np.array([x / 255.0 for x in [63.0, 62.1, 66.7]]))])\n        elif setname == 'train':\n            image_size = 84\n            self.transform = transforms.Compose([\n                transforms.RandomResizedCrop(image_size),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize(np.array([x / 255.0 for x in [125.3, 123.0, 113.9]]),\n                                     np.array([x / 255.0 for x in [63.0, 62.1, 66.7]]))])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        path, label = self.data[i], self.label[i]\n        image = self.transform(Image.open(path).convert('RGB'))\n        return image, label\n\nclass CategoriesSampler():\n\n    def __init__(self, label, n_batch, n_cls, n_per):\n        self.n_batch = n_batch  # the number of iterations in the dataloader\n        self.n_cls = n_cls\n        self.n_per = n_per\n\n        label = np.array(label)  # all data label\n        self.m_ind = []  # the data index of each class\n        for i in range(max(label) + 1):\n            ind = np.argwhere(label == i).reshape(-1)  # all data index of this class\n            ind = torch.from_numpy(ind)\n            self.m_ind.append(ind)  # 列表，0位置表示类0的元素所有索引\n\n    def __len__(self):\n        return self.n_batch\n\n    def __iter__(self):\n        for i_batch in range(self.n_batch):\n            batch = []\n            classes = torch.randperm(len(self.m_ind))[:self.n_cls]  # random sample num_class indexs,e.g. 5\n            for c in classes:\n                l = self.m_ind[c]  # all data indexs of this class\n                pos = torch.randperm(len(l))[:self.n_per]  # sample n_per data index of this class\n                batch.append(l[pos])\n            batch = torch.stack(batch).t().reshape(-1)\n            yield batch\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\ndef conv3x3(in_channels, out_channels):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)   # 之前写的bias=False\n\ndef conv1x1(in_channels, out_channels):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n\nclass Conv_block(nn.Module):\n    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n        super(Conv_block, self).__init__()\n        self.conv = nn.Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n        self.relu = nn.LeakyReLU(0.2)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.relu(x)\n        return x\n\nclass ResBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample, is_pooling=True, drop_rate=0.0):\n        super(ResBlock, self).__init__()\n        self.is_pooling = is_pooling\n        self.conv1 = conv3x3(in_channels, out_channels)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.LeakyReLU(0.2)\n        self.conv2 = conv3x3(out_channels, out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = conv3x3(out_channels, out_channels)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        self.downsample = downsample\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        if self.is_pooling:\n            self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n            out = self.maxpool(out)\n        if self.drop_rate > 0:\n            out = F.dropout(out, p=self.drop_rate, training=self.training, inplace=True)\n        return out\n\n\nclass ResNet12(nn.Module):\n    def __init__(self, channels):\n        super(ResNet12, self).__init__()\n        self.feature_dim = 640\n        self.inplanes = 3\n\n        self.layer1 = self._make_layer(channels[0])\n        self.layer2 = self._make_layer(channels[1])\n        self.layer3 = self._make_layer(channels[2])\n        self.layer4 = self._make_layer(channels[3])\n\n        self.out_dims = channels[3]\n\n    def _make_layer(self, planes):\n        downsample = nn.Sequential(\n            conv1x1(self.inplanes, planes),\n            nn.BatchNorm2d(planes),\n        )\n        block = ResBlock(self.inplanes, planes, downsample)\n        self.inplanes = planes\n        return block\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\nclass ConV4(nn.Module):\n    def __init__(self, channels):\n        super(ConV4, self).__init__()\n        self.in_channels = 3\n        self.feature_dim = 64\n        self.layer1 = nn.Sequential(\n            conv3x3(self.in_channels, channels[0]),\n            nn.BatchNorm2d(channels[0]),\n            nn.LeakyReLU(0.2, True),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n\n        self.layer2 = nn.Sequential(\n            conv3x3(channels[0], channels[1]),\n            nn.BatchNorm2d(channels[1]),\n            nn.LeakyReLU(0.2, True),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n\n        self.layer3 = nn.Sequential(\n            conv3x3(channels[1], channels[2]),\n            nn.BatchNorm2d(channels[2]),\n            nn.LeakyReLU(0.2, True),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n\n        self.layer4 = nn.Sequential(\n            conv3x3(channels[2], channels[3]),\n            nn.BatchNorm2d(channels[3]),\n            nn.LeakyReLU(0.2, True),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\n\ndef resnet12():\n    return ResNet12([64, 160, 320, 640])    # 512x21x21\n\ndef conv4():\n    return ConV4([64, 64, 64, 64])      # 64x21x21\n\ndef resnet12_wide():\n    return ResNet12([64, 160, 320, 640])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass LinearClassifier(nn.Module):\n    def __init__(self, in_dim, out_dim):\n        super(LinearClassifier, self).__init__()\n        self.L = nn.Linear(in_dim, out_dim)\n\n    def forward(self, x):\n        return self.L(x)\n\nclass CosineClassifier(nn.Module):\n    def __init__(self, in_dim, out_dim, gain):\n        super(CosineClassifier, self).__init__()\n        self.gain = gain\n        self.L = nn.Linear(in_dim, out_dim, bias=False)\n\n    def forward(self, x):\n        self.L.weight.data = nn.functional.normalize(self.L.weight.data, dim=1)\n        x = nn.functional.normalize(x)\n        return self.gain*self.L(x)\n\nclass FewShotModel(nn.Module):\n    def __init__(self, args, pretrain_model=None):\n        super(FewShotModel, self).__init__()\n        self.args = args\n        self.training = True\n        self.class_info = None\n        if pretrain_model:\n            self.encoder = nn.Sequential(\n\t\t\t*list(pretrain_model.encoder.children())\n\t\t\t)\n            self.feature_dim = pretrain_model.encoder.feature_dim\n        else:\n            assert args.backbone in [\"ConV4\", \"ResNet12\"]\n            if args.backbone == \"ConV4\":\n                self.encoder = conv4()              # output: 64x21x21\n            else:\n                self.encoder = resnet12()           # output: 512x21x21\n            self.feature_dim = self.encoder.feature_dim\n\n\n        if args.classifier == \"Linear\":\n            self.classifier = LinearClassifier(self.feature_dim, args.num_class)\n        elif args.classifier == \"Cosine\":\n            self.classifier = CosineClassifier(self.feature_dim, args.num_class, 10)\n\n    def forward(self, input, bbox=None):\n        return self.pretrain_classify_forward(input)\n   \n\n    def pretrain_classify_forward(self, x):\n        x = self.encode(x, dense=False).squeeze(-1).squeeze(-1)\n        return self.classifier(x)\n\n\n    def encode(self, x, dense=False):\n        if x.shape.__len__() == 5:  # batch of image patches\n            num_data, num_patch = x.shape[:2]\n            x = x.reshape(-1, x.shape[2], x.shape[3], x.shape[4])\n            x = self.encoder(x)\n            x = F.adaptive_avg_pool2d(x, 1)\n            x = x.reshape(num_data, num_patch, x.shape[1], x.shape[2], x.shape[3])\n            x = x.permute(0, 2, 1, 3, 4)\n            x = x.squeeze(-1)\n            return x\n\n        else:\n            x = self.encoder(x)\n            if dense == False:\n                x = F.adaptive_avg_pool2d(x, 1)\n                return x\n            if self.args.feature_pyramid is not None:\n                x = self.build_feature_pyramid(x)   # 多尺度\n        return x\n    \n    def build_feature_pyramid(self, feature):\n        feature_list = []\n        for size in self.args.feature_pyramid:\n            feature_list.append(F.adaptive_avg_pool2d(feature, size).view(feature.shape[0], feature.shape[1], 1, -1))\n        feature_list.append(feature.view(feature.shape[0], feature.shape[1], 1, -1))\n        out = torch.cat(feature_list, dim=-1)\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport math\nimport scipy as sp\nimport scipy.stats\n\ndef bbox2grid(bbox, w=21, h=21):\n    res = []\n    bbox_num = len(bbox)        # 一张图像中的目标数\n    for i in range(bbox_num):\n        x_min, y_min, x_max, y_max = bbox[i]\n        x_min, y_min, x_max, y_max = math.floor(x_min*w), math.floor(y_min*h), math.ceil(x_max*w), math.ceil(y_max*h)\n        for m in range(x_min, x_max):\n            for n in range(y_min, y_max):\n                res.append((n, m))\n    res = list(set(res))\n    return res\n\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n\ndef save_checkpoint(state, filename='checkpoint.pth.tar'):\n\ttorch.save(state, filename)\n\nclass Averager(object):\n\tdef __init__(self):\n\t\tself.reset()\n\n\tdef reset(self):\n\t\tself.val = 0\n\t\tself.avg = 0\n\t\tself.sum = 0\n\t\tself.count = 0\n\n\tdef update(self, val, n=1):\n\t\tself.val = val\n\t\tself.sum += val * n\n\t\tself.count += n\n\t\tself.avg = self.sum / self.count\n\n\ndef count_acc(logits, label):\n    pred = torch.argmax(logits, dim=1)\n    if torch.cuda.is_available():\n        return (pred == label).type(torch.cuda.FloatTensor).mean().item()\n    else:\n        return (pred == label).type(torch.FloatTensor).mean().item()\n    \ndef ostu(data):\n    num = len(data)\n    sort_data, _ = torch.sort(data)\n    vr = sort_data[-1] - sort_data[0]\n    max_var = 0\n    thr = 0\n    s1 = 0\n    s2 = torch.sum(data)\n    for i, th in enumerate(sort_data):\n        p1 = (i+1)/num\n        p2 = 1-p1\n        s1 += th\n        s2 -= th\n        m1 = s1 / (i+1)\n        m2 = s2 / (num-i-1)\n        var = p1*p2*(m1-m2)**2\n        if var > max_var:\n            thr = th\n            max_var = var\n    return thr\n\ndef mean_confidence_interval(data, confidence=0.95):\n    a = [1.0*np.array(data[i]) for i in range(len(data))]\n    n = len(a)\n    m, se = np.mean(a), scipy.stats.sem(a)\n    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n\n    return m, h","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 第一种方法\nimport random\nfrom scipy.spatial.distance import euclidean\n\n\ndef kmeans(data, k, iterations):\n    res_cent = []\n    min_dis = 100000\n    res_centroids = random.sample(list(data), k)\n    res_ind = []\n    for mr in range(30):\n        dis = 0\n        inds = [[] for _ in range(k)]\n        centroids = random.sample(list(data), k)\n        new_centroids = centroids.copy()\n        for _ in range(iterations):\n            dis = 0\n            clusters = [[] for _ in range(k)]\n            inds = [[] for _ in range(k)]\n            # 分配数据点到最近的聚类中心\n            for ind, point in enumerate(data):\n                distances = [euclidean(point, centroid) for centroid in centroids]\n                closest_centroid_index = np.argmin(distances)\n                clusters[closest_centroid_index].append(point)\n                inds[closest_centroid_index].append(ind)\n                dis += distances[closest_centroid_index]\n\n            # 更新聚类中心\n            for i in range(k):\n                if clusters[i]:\n                    new_centroids[i] = np.mean(clusters[i], axis=0)\n            flag = 0\n            for i in range(k):\n                if euclidean(new_centroids[i], centroids[i]) > 0.01:\n                    flag+=1\n            if flag > 0:\n                centroids = new_centroids\n            else:\n                break\n        if dis<min_dis:\n            min_dis = dis\n            res_centroids = centroids.copy()\n            res_ind = inds.copy()\n    return res_ind\n        \n\ndef few_shot_eval(query, support): \n    feat = support.view(support.shape[0], support.shape[1], -1)\n    feat_s = feat.permute(0, 2, 1)\n    shot_num = feat_s.shape[0]\n    s_ind = []\n    for i in range(shot_num):\n        shot_feat = feat_s[i]\n        s_ind.append(kmeans(shot_feat.cpu().detach().numpy(), 2, 25))\n\n    feat = query.view(query.shape[0], query.shape[1], -1)\n    feat = feat.permute(0, 2, 1)\n    query_num = feat.shape[0]\n    logits = torch.empty((query_num, shot_num)).to(device)\n#     tmp_feat = torch.empty((3, feat.shape[-1])).to(device)\n    for i in range(query_num):\n        q_feat = feat[i]\n        q_ind = kmeans(q_feat.cpu().detach().numpy(), 2, 25)\n        for c in range(shot_num):\n            c_feat = feat_s[c]\n            logit = 0\n            for m in range(2):\n                for n in range(2):\n                    weight_q = torch.empty(25).to(device)\n                    weight_q[q_ind[m]] = 0.6\n                    weight_q[q_ind[1-m]] = 0.4\n                    weight_q = weight_q / torch.sum(weight_q)\n                    q_avg = torch.matmul(weight_q.unsqueeze(0), q_feat)\n                    weight_s = torch.empty(25).to(device)\n                    weight_s[s_ind[c][n]] = 0.6\n                    weight_s[s_ind[c][1-n]] = 0.4\n                    weight_s = weight_s / torch.sum(weight_s)\n                    s_avg = torch.matmul(weight_s.unsqueeze(0), c_feat)\n                    logit_tmp = torch.matmul(F.normalize(q_avg, dim=-1), F.normalize(s_avg, dim=-1).t())\n                    if logit_tmp>logit:\n                        logit = logit_tmp\n            logits[i, c] = logit\n    if shot_num > 5:\n        new_logits = torch.empty((query_num, 5)).to(device)\n        label = torch.arange(5).repeat(5)\n        for i in range(query_num):\n            for c in range(5):\n                ind = (label==c).nonzero().squeeze(-1)\n                new_logits[i, c] = torch.sum(logits[i][ind])\n        return new_logits\n        \n    return logits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 第二种方法\nimport random\nfrom scipy.spatial.distance import euclidean\n\n\ndef kmeans(data, k, iterations):\n    res_cent = []\n    min_dis = 100000\n    res_centroids = random.sample(list(data), k)\n    res_ind = []\n    for mr in range(50):\n        dis = 0\n        inds = [[] for _ in range(k)]\n        centroids = random.sample(list(data), k)\n        new_centroids = centroids.copy()\n        for _ in range(iterations):\n            dis = 0\n            clusters = [[] for _ in range(k)]\n            inds = [[] for _ in range(k)]\n            # 分配数据点到最近的聚类中心\n            for ind, point in enumerate(data):\n                distances = [euclidean(point, centroid) for centroid in centroids]\n                closest_centroid_index = np.argmin(distances)\n                clusters[closest_centroid_index].append(point)\n                inds[closest_centroid_index].append(ind)\n                dis += distances[closest_centroid_index]\n\n            # 更新聚类中心\n            for i in range(k):\n                if clusters[i]:\n                    new_centroids[i] = np.mean(clusters[i], axis=0)\n            flag = 0\n            for i in range(k):\n                if euclidean(new_centroids[i], centroids[i]) > 0.01:\n                    flag+=1\n            if flag > 0:\n                centroids = new_centroids\n            else:\n                break\n        if dis<min_dis:\n            min_dis = dis\n            res_centroids = centroids.copy()\n            res_ind = inds.copy()\n    return res_ind\n        \n\ndef few_shot_eval(query, support): \n    feat = support.view(support.shape[0], support.shape[1], -1)\n    feat = feat.permute(0, 2, 1)\n    label = torch.arange(5).repeat(2)\n    feat_s = torch.empty((5, 2*25, 64)).to(device)\n    for i in range(5):\n        ind = (label==i).nonzero().squeeze(-1)\n        ff = feat[ind]\n        ff = ff.reshape(-1, ff.shape[-1])\n        feat_s[i] = ff\n#     print(feat_s.shape)\n#     print(feat_s)\n    shot_num = feat_s.shape[0]\n    s_ind = []\n    for i in range(shot_num):\n        shot_feat = feat_s[i]\n        s_ind.append(kmeans(shot_feat.cpu().detach().numpy(), 2, 25))\n    feat = query.view(query.shape[0], query.shape[1], -1)\n    feat = feat.permute(0, 2, 1)\n    query_num = feat.shape[0]\n    logits = torch.empty((query_num, shot_num)).to(device)\n#     tmp_feat = torch.empty((3, feat.shape[-1])).to(device)\n    for i in range(query_num):\n        q_feat = feat[i]\n        q_ind = kmeans(q_feat.cpu().detach().numpy(), 2, 25)\n        for c in range(shot_num):\n            c_feat = feat_s[c]\n            logit = 0\n            for m in range(2):\n                for n in range(2):\n                    weight_q = torch.empty(25).to(device)\n                    weight_q[q_ind[m]] = 0.6\n                    weight_q[q_ind[1-m]] = 0.4\n                    weight_q = weight_q / torch.sum(weight_q)\n                    q_avg = torch.matmul(weight_q.unsqueeze(0), q_feat)\n                    weight_s = torch.empty(25*2).to(device)\n                    weight_s[s_ind[c][n]] = 0.6\n                    weight_s[s_ind[c][1-n]] = 0.4\n                    weight_s = weight_s / torch.sum(weight_s)\n                    s_avg = torch.matmul(weight_s.unsqueeze(0), c_feat)\n                    logit_tmp = torch.matmul(F.normalize(q_avg, dim=-1), F.normalize(s_avg, dim=-1).t())\n                    if logit_tmp>logit:\n                        logit = logit_tmp\n            logits[i, c] = logit\n        \n    return logits","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport time\nfrom datetime import datetime\nimport tqdm\nimport torchvision\nimport matplotlib.pyplot as plt\ndevice = \"cuda\"\n\n\nparser = argparse.ArgumentParser()\n# about dataset and network\nparser.add_argument('-dataset', type=str, default='miniimagenet', choices=['miniimagenet', 'cub','tieredimagenet','fc100','tieredimagenet_yao','cifar_fs'])\nparser.add_argument('-data_dir', type=str, default=DATA_DIR, help='dataset path')\nparser.add_argument('-data_split', type=str, default=DATA_SPLIT)\n# about pre-training\nparser.add_argument('-num_class', type=int, default=100)\nparser.add_argument('-max_epoch', type=int, default=200)\nparser.add_argument('-lr', type=float, default=0.1)\nparser.add_argument('-step_size', type=int, default=30)\nparser.add_argument('-gamma', type=float, default=0.2)\nparser.add_argument('-bs', type=int, default=128)\nparser.add_argument('-backbone', type=str, default=\"ResNet12\", choices=[\"ConV4\", \"ResNet12\"])\nparser.add_argument('-classifier', type=str, default=\"Cosine\", choices=[\"Linear\", \"Cosine\"])\n\n# about validation\nparser.add_argument('-set', type=str, default='val', choices=['val', 'test'], help='the set for validation')\nparser.add_argument('-way', type=int, default=5)\nparser.add_argument('-shot', type=int, default=5)\nparser.add_argument('-query', type=int, default=15)\nparser.add_argument('-temperature', type=float, default=12.5)\nparser.add_argument('-metric', type=str, default='cosine')\nparser.add_argument('-simi_metric', type=str, default='cosine')\nparser.add_argument('-num_episode', type=int, default=400)\nparser.add_argument('-random_val_task', action='store_true', default='no', help='random samples tasks for validation in each epoch')\nparser.add_argument('-feature_pyramid', type=str, default=None)\n# about training\nparser.add_argument('-seed', type=int, default=1)\nparser.add_argument('-resume_dir', type=str, default=None)\nparser.add_argument('-print_freq', type=int, default=10)\nargs = parser.parse_args(args=[])\n\n# set_seed(args.seed)\n\ndataset_name = args.dataset\n\nif not args.resume_dir:\n    now = datetime.now()\n    date_string = now.strftime(\"%Y-%m-%d\")\n    train_input_info = dataset_name + '-' + args.backbone + '-' + date_string\n\n    args.save_path = train_input_info\n    if not os.path.exists(args.save_path):\n        os.mkdir(args.save_path)\nelse:\n    args.save_path = args.resume_dir\n\n\n# train info txt\ntxt_save_path = os.path.join(args.save_path, 'opt_resutls.txt')\nF_txt = open(txt_save_path, 'a+')\n\n\nDataset = CUB\ntrainset = Dataset('train', args)\ntrain_loader = DataLoader(dataset=trainset, batch_size=args.bs, shuffle=True, num_workers=0, pin_memory=True)\n\nvalset = Dataset('val', args)\nval_sampler = CategoriesSampler(valset.label, args.num_episode, args.way, args.shot + args.query)\nval_loader = DataLoader(dataset=valset, batch_sampler=val_sampler, num_workers=0, pin_memory=True)\n\ntestset = Dataset('test', args)\ntest_sampler = CategoriesSampler(testset.label, args.num_episode, args.way, args.shot + args.query)\ntest_loader = DataLoader(dataset=testset, batch_sampler=test_sampler, num_workers=8, pin_memory=True)\nif not args.random_val_task:\n    print('fix val set for all epochs')\n    val_loader = [x for x in val_loader]\n\n\nmodel = FewShotModel(args).to(device)\n\n\n# label of query images.\nlabel = torch.arange(args.way, dtype=torch.int8).repeat(args.query)  # shape[75]:012340123401234...\nlabel = label.type(torch.LongTensor)\nlabel = label.to(device)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n\nfor param_group in optimizer.param_groups:\n    print(param_group['lr'])\n\nprint(args)\nprint(args, file=F_txt)\nprint(model)\nprint(model, file=F_txt)\n\n\nglobal_count = 0\n\nbest_prec1 = 0.\n\nresult_list = [args.save_path]\nfor epoch in range(1, args.max_epoch + 1):\n    losses = Averager()\n    vq_losses = Averager()\n    top1 = Averager()\n    val_losses = Averager()\n    prec1_val = Averager()\n    val_emd_losses = Averager()\n    prec1_emd_val = Averager()\n    data_time = Averager()\n    batch_time = Averager()\n    val_batch_time = Averager()\n    val_emd_batch_time = Averager()\n    \n    start_time = time.time()\n    model.train()\n    train_loader_length = len(train_loader)\n    train_iterator = iter(train_loader)\n    end = time.time()\n    print('===================================== Training on the train set =====================================')\n    print('===================================== Training on the train set =====================================', file=F_txt)\n    for i in range(1, train_loader_length+1):\n        global_count = global_count + 1\n        batch = next(train_iterator)\n        data, train_label = [_.to(device) for _ in batch]\n        data_time.update(time.time() - end)\n\n        logits = model(data)\n        loss = F.cross_entropy(logits, train_label)\n        acc = count_acc(logits, train_label)\n        total_loss = loss\n        losses.update(total_loss.item(), args.bs)\n#         vq_losses.update(vq_loss.item(), args.bs)\n        top1.update(acc, args.bs)\n        optimizer.zero_grad()\n        total_loss.backward()\n        optimizer.step()\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print('Eposide-({0}): [{1}/{2}]\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n#                   'VQ Loss {vq_loss.val:.3f} ({vq_loss.avg:.3f})\\t'\n                  'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n                epoch, i, train_loader_length, batch_time=batch_time, data_time=data_time, loss=losses,\n                top1=top1))\n\n            print('Eposide-({0}): [{1}/{2}]\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                  'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n                epoch, i, train_loader_length, batch_time=batch_time, data_time=data_time, loss=losses,\n                top1=top1), file=F_txt)\n\n    print('===================================== Validation on the val set =====================================')\n    print('===================================== validation on the val set =====================================',\n          file=F_txt)\n\n    model.eval()\n\n    val_iterator = iter(val_loader)\n    val_print_freq = 10 #args.num_episode / 20 -1\n    for i in range(1, args.num_episode+1):\n        batch = next(val_iterator)\n        data, _ = [_.to(device) for _ in batch]\n        k = args.way * args.shot\n        data_shot, data_query = data[:k], data[k:]\n        #episode learning\n        with torch.no_grad():\n            feat_s, feat_q = model.encode(data_shot, dense=True), model.encode(data_query, dense=True)\n\n        logits = few_shot_eval(feat_q, feat_s)\n        loss = F.cross_entropy(logits, label)\n        acc = count_acc(logits, label)\n\n        val_losses.update(loss, args.shot * args.query)\n        prec1_val.update(acc, args.shot * args.query)\n        val_batch_time.update(time.time()-end)\n        end = time.time()\n        if i % val_print_freq == 0:\n            print('Eposide-({0}): [{1}/{2}]\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n                epoch, i, args.num_episode, batch_time=val_batch_time, loss=val_losses,\n                top1=prec1_val))\n\n            print('Eposide-({0}): [{1}/{2}]\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n                epoch, i, args.num_episode, batch_time=val_batch_time, loss=val_losses,\n                top1=prec1_val), file=F_txt)\n\n\n    if prec1_val.avg > best_prec1:\n        best_prec1 = prec1_val.avg\n        save_checkpoint(\n            {\n                'epoch_index': epoch,\n                'state_dict': model.state_dict(),\n                'best_prec1': best_prec1,\n                'optimizer': optimizer.state_dict()\n            }, os.path.join(args.save_path, 'model_best.pth.tar'))\n\n    if epoch % 10 == 0:\n        filename = os.path.join(args.save_path, 'epoch_%d.pth.tar' % epoch)\n        save_checkpoint(\n            {\n                'epoch_index': epoch,\n                'state_dict': model.state_dict(),\n                'best_prec1': best_prec1,\n                'optimizer': optimizer.state_dict()\n            }, filename)\n    save_checkpoint(\n        {\n            'epoch_index': epoch,\n            'state_dict': model.state_dict(),\n            'best_prec1': best_prec1,\n            'optimizer': optimizer.state_dict()\n        }, os.path.join(args.save_path, 'tmp.pth.tar'))\n\n    lr_scheduler.step()\nF_txt.close()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}